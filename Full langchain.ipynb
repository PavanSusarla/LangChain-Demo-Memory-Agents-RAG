{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2192b26-e96a-4c22-aff4-f2bacc542923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T13:53:30.606072Z",
     "iopub.status.busy": "2025-10-08T13:53:30.605373Z",
     "iopub.status.idle": "2025-10-08T13:54:30.067964Z",
     "shell.execute_reply": "2025-10-08T13:54:30.064577Z",
     "shell.execute_reply.started": "2025-10-08T13:53:30.606020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great! Chennai has a growing tech scene, and as an ML Engineer, you have a lot of opportunities to work on exciting projects. Are you currently working on any specific machine learning projects, or are you looking for resources, networking opportunities, or anything else related to your field?\n",
      "\n",
      "I donâ€™t have the ability to remember personal information about users or past interactions. Each conversation is treated independently, and I donâ€™t retain any details once the session ends. How can I assist you today?\n",
      "\n",
      "\n",
      "\n",
      "That's great! Football is a popular sport enjoyed by millions around the world. Do you have a favorite team or player? Or is there a particular league or competition you follow?\n",
      "\n",
      "That's great to hear! Cricket is a fascinating sport with a rich history and a passionate following around the world. Do you have a favorite team or player? Or is there a particular format of the game you enjoy, like Test matches, One Day Internationals, or T20?\n",
      "\n",
      "That's great! As a data analyst, you likely work with data to extract insights, create reports, and support decision-making processes. What specific tasks or projects are you currently working on? Or do you have any questions or topics you'd like to discuss related to data analysis?\n",
      "\n",
      "That's great! Chess is a fascinating game that combines strategy, tactics, and skill. Do you have a favorite opening, or are you looking to improve in a specific area of your game?\n",
      "\n",
      "That's great to hear! Python is a versatile and powerful programming language that is widely used for various applications, including web development, data analysis, artificial intelligence, scientific computing, and more. What do you enjoy most about Python? Are there any specific projects or areas you're interested in exploring?\n",
      "\n",
      "I'm sorry, but I don't have access to previous conversations or any context beyond this current interaction. If you could provide more details or clarify what you're referring to, I'd be happy to help!\n",
      "\n",
      "\n",
      "\n",
      "Got it! Remembered that Pavan likes cricket and Python..\n",
      "\n",
      "Pavan likes cricket and Python..\n",
      "\n",
      "\n",
      "\n",
      "Where does Ravi live? Ravi lives in Mumbai.\n",
      "\n",
      "\n",
      "\n",
      "In healing hands of code, compassion thrives,  \n",
      "AI whispers hope, where innovation drives.\n",
      "\n",
      "\n",
      "\n",
      "**Awaken Your Senses with Sunbucks Coffee!**\n",
      "\n",
      "At Sunbucks Coffee, we believe that every cup of coffee is an experience waiting to unfold. Imagine the rich aroma of freshly brewed coffee wafting through the air, inviting you to take a moment for yourself. Our expertly sourced beans are handpicked from the finest coffee-growing regions around the world, ensuring that each sip is a journey of flavor and delight.\n",
      "\n",
      "Whether you prefer the bold intensity of a dark roast or the smooth, subtle notes of a light blend, our diverse selection caters to every palate. Each cup is crafted with care, using artisanal brewing methods that bring out the unique characteristics of our beans. \n",
      "\n",
      "But itâ€™s not just about the coffee; itâ€™s about the experience. Step into our cozy cafÃ©, where the warm ambiance and friendly baristas create a welcoming atmosphere. Take a break from your busy day, catch up with friends, or simply enjoy a moment of solitude with your favorite brew. \n",
      "\n",
      "At Sunbucks Coffee, weâ€™re committed to sustainability and ethical sourcing, ensuring that every cup you enjoy supports the farmers and communities that make it possible. \n",
      "\n",
      "So why wait? Awaken your senses and elevate your coffee experience with Sunbucks Coffee. Visit us today and discover the perfect blend that speaks to you. Your journey to a more vibrant day starts with just one sip!\n",
      "\n",
      "\n",
      "\n",
      "Good night -> Bonne nuit\n",
      "\n",
      "\n",
      "\n",
      "320\n",
      "\n",
      "\n",
      "\n",
      "The weather in Chennai is sunny, and 10 multiplied by 5 is 50.\n",
      "\n",
      "\n",
      "\n",
      "That's great! Blue is a popular color and is often associated with calmness and tranquility. Do you have a specific shade of blue that you like the most?\n",
      "```\n",
      "\n",
      "Your favorite color is blue, as you mentioned earlier! Do you have a specific shade of blue that you prefer?\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Pavan is a Machine Learning Engineer from Chennai.\n",
      "\n",
      "\n",
      "\n",
      "Nice to meet you, Pavan! How can I assist you today?\n",
      "```\n",
      "\n",
      "I don't have access to personal information, so I can't determine where you live. However, if you have any questions or need assistance with something else, feel free to ask!\n",
      "```\n",
      "\n",
      "The result of 12 multiplied by 12 is 144. If you have any more questions or need further assistance, feel free to ask!\n",
      "\n",
      "\n",
      "\n",
      "The Jagannath Temple is in Puri, Odisha.\n",
      "The coffee chain mentioned is Sunbucks.\n",
      "\n",
      "\n",
      "\n",
      "Python is commonly used for machine learning (ML).\n",
      "The translation of \"Hello\" to French is \"Bonjour.\"\n",
      "The result of 50 multiplied by 7 is 350.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ðŸ§© LangChain Memory & Agent Demo (v0.2+ Compatible)\n",
    "# ==========================================================\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain, ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.memory import ChatMessageHistory, ConversationSummaryBufferMemory, ConversationBufferMemory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Initialize LLM and Embeddings\n",
    "# ----------------------------------------------------------\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ§  Q1: Chatbot with ConversationSummaryBufferMemory\n",
    "# ----------------------------------------------------------\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=llm)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "chat = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "print(chat.invoke({\"input\": \"I live in Chennai and work as ML Engineer.\"}, config={\"configurable\": {\"session_id\": \"user1\"}}).content)\n",
    "print()\n",
    "print(chat.invoke({\"input\": \"What do you remember about me?\"}, config={\"configurable\": {\"session_id\": \"user1\"}}).content)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸªŸ Q2: Chatbot with Limited Memory (Window of 3 messages)\n",
    "# ----------------------------------------------------------\n",
    "window_history = ChatMessageHistory()\n",
    "\n",
    "def limited_history(session_id):\n",
    "    msgs = window_history.messages[-6:]\n",
    "    window_history.clear()\n",
    "    for m in msgs:\n",
    "        window_history.add_message(m)\n",
    "    return window_history\n",
    "\n",
    "chat_window = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    limited_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "messages = [\"I like football.\", \"I enjoy cricket.\", \"I work as data analyst.\", \"I play chess.\", \"I love Python.\"]\n",
    "for msg in messages:\n",
    "    print(chat_window.invoke({\"input\": msg}, config={\"configurable\": {\"session_id\": \"user2\"}}).content)\n",
    "    print()\n",
    "\n",
    "print(chat_window.invoke({\"input\": \"What did I say first?\"}, config={\"configurable\": {\"session_id\": \"user2\"}}).content)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ§¾ Q3: Simulated Knowledge Graph Memory\n",
    "# ----------------------------------------------------------\n",
    "facts = {}\n",
    "\n",
    "def remember_facts(user_input):\n",
    "    if \"likes\" in user_input:\n",
    "        name, likes = user_input.split(\"likes\")\n",
    "        facts[name.strip()] = likes.strip()\n",
    "        return f\"Got it! Remembered that {name.strip()} likes {likes.strip()}.\"\n",
    "    elif \"What does\" in user_input:\n",
    "        name = user_input.split(\" \")[2]\n",
    "        return f\"{name} likes {facts.get(name, 'Unknown')}.\"\n",
    "    else:\n",
    "        return \"Tell me something new!\"\n",
    "\n",
    "print(remember_facts(\"Pavan likes cricket and Python.\"))\n",
    "print()\n",
    "print(remember_facts(\"What does Pavan like?\"))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ‘¥ Q4: Entity Memory (Manual Entity Recall)\n",
    "# ----------------------------------------------------------\n",
    "entities = {\"Pavan\": \"Chennai\", \"Ravi\": \"Mumbai\"}\n",
    "print(f\"Where does Ravi live? Ravi lives in {entities['Ravi']}.\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# âœï¸ Q5: LLMChain with PromptTemplate\n",
    "# ----------------------------------------------------------\n",
    "template = \"Write a 2-line poem about {topic}\"\n",
    "prompt = PromptTemplate(input_variables=[\"topic\"], template=template)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run({\"topic\": \"AI in Healthcare\"}).strip())\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ”— Q6: SimpleSequentialChain Example\n",
    "# ----------------------------------------------------------\n",
    "chain1 = LLMChain(llm=llm, prompt=PromptTemplate(template=\"Generate a slogan for {product}\", input_variables=[\"product\"]))\n",
    "chain2 = LLMChain(llm=llm, prompt=PromptTemplate(template=\"Expand the slogan: {slogan} into full ad copy\", input_variables=[\"slogan\"]))\n",
    "seq_chain = SimpleSequentialChain(chains=[chain1, chain2])\n",
    "print(seq_chain.run(\"Sunbucks Coffee\").strip())\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸŒ Q7: Few-shot Translation PromptTemplate\n",
    "# ----------------------------------------------------------\n",
    "few_shot_template = \"\"\"\n",
    "Translate the following English words to French.\n",
    "Hello -> Bonjour\n",
    "Goodbye -> Au revoir\n",
    "Now translate {word} ->\n",
    "\"\"\"\n",
    "few_shot_prompt = PromptTemplate(input_variables=[\"word\"], template=few_shot_template)\n",
    "translation_chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "print(translation_chain.run({\"word\": \"Good night\"}).strip())\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ§® Q8: Agent with Calculator Tool\n",
    "# ----------------------------------------------------------\n",
    "def calculator_tool(query: str) -> str:\n",
    "    try:\n",
    "        return str(eval(query))\n",
    "    except:\n",
    "        return \"Error in calculation\"\n",
    "\n",
    "tools = [Tool(name=\"Calculator\", func=calculator_tool, description=\"Solves math expressions\")]\n",
    "agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False)\n",
    "print(agent.invoke(\"Calculate 75*4 + 20\")[\"output\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸŒ¦ï¸ Q9: Agent with Calculator + Weather Tool\n",
    "# ----------------------------------------------------------\n",
    "def weather_tool(query: str) -> str:\n",
    "    return \"Sunny in Chennai\"\n",
    "\n",
    "tools_weather = [\n",
    "    Tool(name=\"Calculator\", func=calculator_tool, description=\"Math\"),\n",
    "    Tool(name=\"Weather\", func=weather_tool, description=\"Weather info\")\n",
    "]\n",
    "agent_weather = initialize_agent(tools=tools_weather, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False)\n",
    "print(agent_weather.invoke(\"What is the weather in Chennai and calculate 10*5\")[\"output\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ§  Q10: Stateful Agent with Memory (Fixed)\n",
    "# ----------------------------------------------------------\n",
    "memory_agent = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "agent_mem = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory_agent,\n",
    "    verbose=False\n",
    ")\n",
    "print(agent_mem.invoke({\"input\": \"My favorite color is Blue\", \"chat_history\": []})[\"output\"])\n",
    "print()\n",
    "print(agent_mem.invoke({\"input\": \"What is my favorite color?\", \"chat_history\": []})[\"output\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ“š Q11: Agent with RAG Tool (Chroma)\n",
    "# ----------------------------------------------------------\n",
    "docs = [\"Pavan is a Machine Learning Engineer in Chennai.\"]\n",
    "vectorstore = Chroma.from_texts(docs, embedding=embeddings, persist_directory=\"chroma_rag\")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "def rag_search(q):\n",
    "    docs = retriever.get_relevant_documents(q)\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "rag_tool = Tool(name=\"RAG Search\", func=rag_search, description=\"Search documents using vectorstore\")\n",
    "agent_rag = initialize_agent(\n",
    "    tools=[rag_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False\n",
    ")\n",
    "print(agent_rag.invoke(\"Who is Pavan and where is he from?\")[\"output\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ§® Q12: Agent with Memory + RAG + Calculator\n",
    "# ----------------------------------------------------------\n",
    "agent_rag_mem = initialize_agent(\n",
    "    tools=[rag_tool, Tool(name=\"Calculator\", func=calculator_tool, description=\"Math\")],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True),\n",
    "    verbose=False\n",
    ")\n",
    "print(agent_rag_mem.invoke({\"input\": \"My name is Pavan\", \"chat_history\": []})[\"output\"])\n",
    "print()\n",
    "print(agent_rag_mem.invoke({\"input\": \"Where do I live?\", \"chat_history\": []})[\"output\"])\n",
    "print()\n",
    "print(agent_rag_mem.invoke({\"input\": \"Calculate 12*12\", \"chat_history\": []})[\"output\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ•‰ï¸ Q13: Retrieval QA Chain (Chroma)\n",
    "# ----------------------------------------------------------\n",
    "temple_docs = [\"Jagannath Temple is in Puri, Odisha.\", \"Meenakshi Temple is in Madurai, Tamil Nadu.\"]\n",
    "temple_store = Chroma.from_texts(temple_docs, embedding=embeddings, persist_directory=\"temple_rag\")\n",
    "temple_retriever = temple_store.as_retriever()\n",
    "temple_qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=temple_retriever)\n",
    "print(temple_qa.invoke({\"question\": \"Where is the Jagannath temple?\", \"chat_history\": []})[\"answer\"])\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ§­ Q14: FAISS Retrieval\n",
    "# ----------------------------------------------------------\n",
    "faiss_store = FAISS.from_texts([\"Sunbucks is a coffee chain.\"], embedding=embeddings)\n",
    "faiss_retriever = faiss_store.as_retriever()\n",
    "faiss_qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=faiss_retriever)\n",
    "print(faiss_qa.invoke({\"question\": \"Which coffee chain is mentioned?\", \"chat_history\": []})[\"answer\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ’¾ Q15: Multi-document RAG Retrieval\n",
    "# ----------------------------------------------------------\n",
    "doc_texts = [\"Python is a programming language.\", \"SQL is used for databases.\", \"Python can be used for ML.\"]\n",
    "doc_store = Chroma.from_texts(doc_texts, embedding=embeddings, persist_directory=\"ml_docs\")\n",
    "doc_retriever = doc_store.as_retriever()\n",
    "doc_qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=doc_retriever)\n",
    "print(doc_qa.invoke({\"question\": \"Which language is used for ML?\", \"chat_history\": []})[\"answer\"])\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ðŸ”¤ Q16: Agent with Translator + Calculator (Fixed chat_history)\n",
    "# ----------------------------------------------------------\n",
    "translator_tool = Tool(\n",
    "    name=\"Translator\", \n",
    "    func=lambda x: \"Bonjour\" if \"Hello\" in x else \"Unknown\", \n",
    "    description=\"Translate English to French\"\n",
    ")\n",
    "agent_dynamic = initialize_agent(\n",
    "    tools=[translator_tool, Tool(name=\"Calculator\", func=calculator_tool, description=\"Math\")],\n",
    "    llm=llm, \n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "    verbose=False\n",
    ")\n",
    "print(agent_dynamic.invoke({\"input\": \"Translate 'Hello' to French\", \"chat_history\": []})[\"output\"])\n",
    "print(agent_dynamic.invoke({\"input\": \"Calculate 50*7\", \"chat_history\": []})[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc5b78d8-4369-45ed-b85f-896299d14fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T14:24:02.675123Z",
     "iopub.status.busy": "2025-10-08T14:24:02.674655Z",
     "iopub.status.idle": "2025-10-08T14:24:33.891735Z",
     "shell.execute_reply": "2025-10-08T14:24:33.890528Z",
     "shell.execute_reply.started": "2025-10-08T14:24:02.675101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"Hello\" to French is \"Bonjour,\" and the result of 12 multiplied by 12 is 144.\n",
      "Pavan is a common name in India and can refer to various individuals. Without more context, it's difficult to determine which specific Pavan you are referring to. It could be a person in popular culture, a public figure, or someone in your personal life. Could you provide more details?\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "That's great to hear! Working as a Machine Learning Engineer in Chennai must be exciting, given the city's growing tech scene. If you have any questions about machine learning, projects you're working on, or anything else, feel free to ask!\n",
      "```\n",
      "You mentioned that you work in Chennai as a Machine Learning Engineer. If you have any specific questions or topics you'd like to discuss related to your work, feel free to share!\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Python is commonly used for machine learning (ML).\n",
      "Pandas and NumPy are Python libraries used for data analysis.\n",
      "\n",
      "\n",
      "\n",
      "Here are the results of your requests:\n",
      "1. \"Hello\" in French is \"Bonjour.\"\n",
      "2. The result of 20 * 5 is 100.\n",
      "3. Python supports machine learning and AI, with libraries such as Pandas and NumPy for data analysis, and SQL for database management and analytics. If you need more specific information about Python ML libraries, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ðŸ§© Q17: Multi-tool Agent with Dynamic Prompt & Memory\n",
    "# ==========================================================\n",
    "dynamic_tools = [\n",
    "    Tool(name=\"Calculator\", func=calculator_tool, description=\"Math expressions\"),\n",
    "    Tool(name=\"Translator\", func=lambda x: \"Bonjour\" if \"Hello\" in x else \"Unknown\", description=\"English -> French\"),\n",
    "    rag_tool\n",
    "]\n",
    "\n",
    "dynamic_agent = initialize_agent(\n",
    "    tools=dynamic_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(dynamic_agent.invoke({\"input\": \"Translate 'Hello' to French and calculate 12*12\", \"chat_history\": []})[\"output\"])\n",
    "print(dynamic_agent.invoke({\"input\": \"Who is Pavan?\", \"chat_history\": []})[\"output\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# ðŸ§  Q18: Conversational Agent with Summary Memory\n",
    "# ==========================================================\n",
    "summary_memory_agent = initialize_agent(\n",
    "    tools=[rag_tool, Tool(name=\"Calculator\", func=calculator_tool, description=\"Math\")],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=ConversationSummaryBufferMemory(llm=llm, memory_key=\"chat_history\"),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(summary_memory_agent.invoke({\"input\": \"I work in Chennai as ML Engineer\", \"chat_history\": []})[\"output\"])\n",
    "print(summary_memory_agent.invoke({\"input\": \"Where do I work?\", \"chat_history\": []})[\"output\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# ðŸ“š Q19: Multi-document RAG Retrieval with Follow-up\n",
    "# ==========================================================\n",
    "multi_docs = [\n",
    "    \"Python supports machine learning and AI.\",\n",
    "    \"SQL is used for database management and analytics.\",\n",
    "    \"Pandas and NumPy are Python libraries for data analysis.\"\n",
    "]\n",
    "\n",
    "multi_doc_store = Chroma.from_texts(multi_docs, embedding=embeddings, persist_directory=\"multi_doc_rag\")\n",
    "multi_retriever = multi_doc_store.as_retriever()\n",
    "multi_doc_qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=multi_retriever)\n",
    "\n",
    "print(multi_doc_qa.invoke({\"question\": \"Which language is used for ML?\", \"chat_history\": []})[\"answer\"])\n",
    "print(multi_doc_qa.invoke({\"question\": \"Which Python libraries are used for data analysis?\", \"chat_history\": []})[\"answer\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# ðŸ”— Q20: Agent + Multi-document RAG + Calculator + Translator\n",
    "# ==========================================================\n",
    "combined_tools = [\n",
    "    Tool(name=\"Calculator\", func=calculator_tool, description=\"Math\"),\n",
    "    Tool(name=\"Translator\", func=lambda x: \"Bonjour\" if \"Hello\" in x else \"Unknown\", description=\"English->French\"),\n",
    "    Tool(name=\"Multi-doc RAG\", func=lambda q: \"\\n\".join([d.page_content for d in multi_retriever.get_relevant_documents(q)]), description=\"Search multi-documents\")\n",
    "]\n",
    "\n",
    "combined_agent = initialize_agent(\n",
    "    tools=combined_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(combined_agent.invoke({\"input\": \"Translate 'Hello' to French, calculate 20*5 and find info on Python ML libraries\", \"chat_history\": []})[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce8a8b-1368-4dc7-93e0-ffb3b6a01ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
